{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import speech_recognition as sr\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Speech Emotion Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Functions to Handle Feature Extraction and Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from sound file - mfcc, chroma, mel\n",
    "def extract_features(file, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to load data and extract features for each sound file\n",
    "def load_data(directory):\n",
    "    x = []\n",
    "    y = []\n",
    "    for file in glob.glob(f\"{directory}/Actor_*/*.wav\"):\n",
    "        filename=os.path.basename(file)\n",
    "        emotion=emotions[filename.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_features(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Audio Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get directory of sound files\n",
    "dirloc = os.path.join(os.getcwd(), \"speech-emotion-recognition-ravdess-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide RAVDESS emotions for encoding\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "# Observed emotions\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load audio data and extract features\n",
    "x, y = load_data(dirloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform x to array\n",
    "X = np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the audio dataset into the Training and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio dataset into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614 154\n"
     ]
    }
   ],
   "source": [
    "# Review number of samples in each dataset\n",
    "print(X_train.shape[0], X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "# Review number of features\n",
    "print(f'Features extracted: {X_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLPClassifier Model with Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLPClassifier instance from Sci-Kit Learn - multi-layer perceptron classifier utilizes internal neural network for classification\n",
    "classifier = MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit MLPClassifier model with training data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Audio Emotion Based on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict values based on test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  2  1  1]\n",
      " [ 6 26  3  4]\n",
      " [ 2  5 21  4]\n",
      " [ 2  6  3 34]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7467532467532467"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix and calculate accuracy score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict New Result with New Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dirloc = os.path.join(os.getcwd(), 'Prediction_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_file = pred_dirloc + '/John F. Kennedy - The Declaration of Independence.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(x_pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mono = librosa.to_mono(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft=np.abs(librosa.stft(y_mono))\n",
    "result=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs=np.mean(librosa.feature.mfcc(y=y_mono, sr=sr, n_mfcc=40).T, axis=0)\n",
    "result=np.hstack((result, mfccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sr).T,axis=0)\n",
    "result=np.hstack((result, chroma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel=np.mean(librosa.feature.melspectrogram(y_mono, sr=sample_rate).T,axis=0)\n",
    "result=np.hstack((result, mel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred_new = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_new = classifier.predict(x_pred_new.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fearful']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After providing a clip of JFK presenting the Declaration of Independence, the model provided a result of \"Fearful.\" This means that the model recognized several measures within the speakers voice which indicated an underlying tone of fear. This is very, very interesting, and we will explore this further in part 2 when we analyze the text sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract text from each sound file and detect sentiment\n",
    "def get_text(directory):\n",
    "    xt = []\n",
    "    yt = []\n",
    "    for file in glob.glob(f\"{directory}/Actor_*/*.wav\"):\n",
    "        try:\n",
    "            text = extract_text(file)\n",
    "            sia = SIA()\n",
    "            pol_score = sia.polarity_scores(text)\n",
    "            sentiment = 0\n",
    "            if pol_score[\"compound\"] > 0.2:\n",
    "                sentiment = 1\n",
    "            elif pol_score[\"compound\"] < -0.2:\n",
    "                sentiment = -1\n",
    "            else:\n",
    "                sentiment = 0\n",
    "            xt.append(text)\n",
    "            yt.append(sentiment)\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "    return xt, yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize speech recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Extract text from sound file\n",
    "def extract_text(file):\n",
    "    with sr.AudioFile(file) as source:\n",
    "        # load audio\n",
    "        audio_data = r.record(source)\n",
    "        # convert speech to text\n",
    "        text = r.recognize_google(audio_data)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data and analyze sentiment\n",
    "xt, yt = get_text(dirloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for subdir in os.listdir(dirloc):\n",
    "    #subdir_folder = os.path.join(dirloc,subdir)\n",
    "   # if os.path.isdir(subdir_folder):\n",
    "       # for file in os.listdir(subdir_folder):\n",
    "           # filename = os.path.join(subdir_folder, file)\n",
    "            #extract_features(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
